{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KreNpqQWnde",
    "outputId": "06801c0e-708c-4731-c724-fb88b6aefb55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in /home/oikantik/anaconda3/lib/python3.9/site-packages (0.6.0)\n",
      "Requirement already satisfied: requests in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torchtext==0.6.0) (2.27.1)\n",
      "Requirement already satisfied: six in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: torch in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torchtext==0.6.0) (2.0.0)\n",
      "Requirement already satisfied: tqdm in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torchtext==0.6.0) (4.64.0)\n",
      "Requirement already satisfied: sentencepiece in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torchtext==0.6.0) (0.1.99)\n",
      "Requirement already satisfied: numpy in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torchtext==0.6.0) (1.21.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.6.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.6.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.6.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.6.0) (2021.10.8)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (10.2.10.91)\n",
      "Requirement already satisfied: filelock in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (11.7.99)\n",
      "Requirement already satisfied: networkx in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (2.7.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (11.7.91)\n",
      "Requirement already satisfied: typing-extensions in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (11.10.3.66)\n",
      "Requirement already satisfied: sympy in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (1.10.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from torch->torchtext==0.6.0) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/oikantik/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchtext==0.6.0) (61.2.0)\n",
      "Requirement already satisfied: wheel in /home/oikantik/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchtext==0.6.0) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/oikantik/anaconda3/lib/python3.9/site-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.26.1)\n",
      "Requirement already satisfied: lit in /home/oikantik/anaconda3/lib/python3.9/site-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from jinja2->torch->torchtext==0.6.0) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from sympy->torch->torchtext==0.6.0) (1.2.1)\n",
      "Requirement already satisfied: wget in /home/oikantik/anaconda3/lib/python3.9/site-packages (3.2)\n",
      "Requirement already satisfied: gdown in /home/oikantik/anaconda3/lib/python3.9/site-packages (4.7.1)\n",
      "Requirement already satisfied: tqdm in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: six in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: filelock in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: requests[socks] in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (2.27.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: gdown in /home/oikantik/anaconda3/lib/python3.9/site-packages (4.7.1)\n",
      "Requirement already satisfied: tqdm in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: filelock in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: requests[socks] in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (2.27.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: six in /home/oikantik/anaconda3/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/oikantik/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0\n",
    "# import locale\n",
    "# locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "! pip install wget\n",
    "! pip install gdown\n",
    "! pip install --upgrade gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "wYmZkdTHV1gb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import gdown\n",
    "from tqdm import tqdm\n",
    "# import wandb\n",
    "from io import open\n",
    "import string, time, math\n",
    "import wget\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "# from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "# import numpy as np\n",
    "import spacy\n",
    "# import random\n",
    "# from torch.utils.tensorboard import SummaryWriter # to print to tensorboard\n",
    "# from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "gaw2m7L5Dj0j"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# CUDA\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# torch.backends.cudnn.deterministic=True\n",
    "# torch.backends.cudnn.benchmark=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "q87jZlq8D--z"
   },
   "outputs": [],
   "source": [
    "# Getting the Dataset\n",
    "url = 'https://drive.google.com/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download'\n",
    "# filename = os.path.basename(url)\n",
    "# print(filename)\n",
    "\n",
    "if not os.path.exists(\"aksharantar_sampled\"):\n",
    "  filename = gdown.download(url = url, quiet=False, fuzzy=True)\n",
    "  print(filename)\n",
    "  with ZipFile(filename, 'r') as z:\n",
    "    print('Extracting files...')\n",
    "    z.extractall()\n",
    "    print('Done!')\n",
    "  os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1cP5vkMgOD3",
    "outputId": "b57b6328-3e95-4dd0-9c9c-f46b35bc69ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "eng_alpha = 'abcdefghijklmnopqrstuvwxyz'\n",
    "pad_char = '<PAD>'\n",
    "\n",
    "eng_alpha2idx = {pad_char: 0}\n",
    "for index, alpha in enumerate(eng_alpha):\n",
    "  eng_alpha2idx[alpha] = index+1\n",
    "\n",
    "print(eng_alpha2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beH3ItF4gTTd",
    "outputId": "72fe6c23-c7e3-4dd5-8504-0605cfcfb771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ', 'ॿ']\n",
      "{'<PAD>': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
     ]
    }
   ],
   "source": [
    "# Bengali Unicode Hex Range: 2432-2558\n",
    "# Hindi Unicode Hex Range: 2304-2431\n",
    "\n",
    "min_range = 2304\n",
    "max_range = 2431\n",
    "\n",
    "# if indic_lang == 'ben':\n",
    "#   min_range = 2432\n",
    "#   max_range = 2558\n",
    "# elif indic_lang == 'hindi':\n",
    "#   min_range = 2304\n",
    "#   max_range = 2431\n",
    "\n",
    "indic_alpha = [chr(alpha) for alpha in range(min_range, max_range + 1)]\n",
    "print(indic_alpha)\n",
    "indic_alpha_size = len(indic_alpha)\n",
    "\n",
    "indic_alpha2idx = {pad_char: 0}\n",
    "for index, alpha in enumerate(indic_alpha):\n",
    "  indic_alpha2idx[alpha] = index+1\n",
    "\n",
    "print(indic_alpha2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tNrcqaQQ6j-5"
   },
   "outputs": [],
   "source": [
    "indic_idx2alpha = {v: k for k, v in indic_alpha2idx.items()}\n",
    "eng_idx2alpha = {v: k for k, v in eng_alpha2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "3j6vZGlyEuKo"
   },
   "outputs": [],
   "source": [
    "def tokenize_indic(string):\n",
    "  # return string.split()\n",
    "  char_list =  [*string]\n",
    "  char_list = [indic_alpha2idx[char] for char in char_list]\n",
    "  return char_list\n",
    "\n",
    "def tokenize_eng(string):\n",
    "  # return string.split()\n",
    "  char_list =  [*string]\n",
    "  char_list = [eng_alpha2idx[char] for char in char_list]\n",
    "  return char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYEkyS3KLRh1",
    "outputId": "771a478e-5377-4f1b-d003-0db86a4e7522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 64, 41, 78, 39, 78, 48, 63]\n",
      "[8, 5, 12, 12, 15]\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_indic('बिन्द्या'))\n",
    "print(tokenize_eng('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "0PulDBIPFWhj"
   },
   "outputs": [],
   "source": [
    "# Change Indic Language here\n",
    "# indic_lang = 'ben'\n",
    "indic_lang = 'hin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "FCuwdH7VHXE1"
   },
   "outputs": [],
   "source": [
    "# importing python package\n",
    "import pandas as pd\n",
    "  \n",
    "file_names = ['test', 'train', 'valid']\n",
    "\n",
    "for index, file_name in enumerate(file_names):\n",
    "  # read contents of csv file\n",
    "  file = pd.read_csv(f'aksharantar_sampled/{indic_lang}/{indic_lang}_{file_name}.csv')\n",
    "  # print(\"\\nOriginal file:\")\n",
    "  # print(file)\n",
    "    \n",
    "  # adding header\n",
    "  headerList = ['eng', f'{indic_lang}']\n",
    "    \n",
    "  # converting data frame to csv\n",
    "  file.to_csv(f'aksharantar_sampled/{indic_lang}/{indic_lang}_{file_name}.csv', header=headerList, index=False)\n",
    "    \n",
    "  # display modified csv file\n",
    "  # file2 = pd.read_csv(f'aksharantar_sampled/{indic_lang}/{indic_lang}_valid_2.csv')\n",
    "  # print('\\nModified file:')\n",
    "  # print(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "gUYK7Us1EDqD"
   },
   "outputs": [],
   "source": [
    "eng = Field(sequential=True, use_vocab=True, tokenize=tokenize_eng, init_token='<sos>', eos_token='<eos>')\n",
    "indic = Field(sequential=True, use_vocab=True, tokenize=tokenize_indic, init_token='<sos>', eos_token='<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tig4Kqp0MUsd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "5RFKlw5MEx6l"
   },
   "outputs": [],
   "source": [
    "fields={'eng': ('eng', eng), f'{indic_lang}': ('indic', indic)}\n",
    "\n",
    "path_name = f'aksharantar_sampled/{indic_lang}'\n",
    "train_name = f'{indic_lang}_train.csv'\n",
    "val_name = f'{indic_lang}_valid.csv'\n",
    "test_name = f'{indic_lang}_test.csv'\n",
    "train_data, val_data, test_data = TabularDataset.splits(\n",
    "    path= path_name,\n",
    "    train=train_name,\n",
    "    validation=val_name,\n",
    "    test=test_name,\n",
    "    format='csv',\n",
    "    fields=fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwT-AtD0MaKK",
    "outputId": "16e7ac88-caa4-44af-d547-800e191afbf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eng', 'indic'])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIaEB78IKrdL",
    "outputId": "5384ea01-792f-4175-a090-c03a4aad461d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([[2, 9, 14, 4, 8, 25, 1], [45, 64, 41, 78, 39, 78, 48, 63]])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOx6Q3ZeAx6p",
    "outputId": "5d7049cd-e605-4986-991c-7470cc0f65f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 9, 14, 4, 8, 25, 1]\n",
      "b\n",
      "i\n",
      "n\n",
      "d\n",
      "h\n",
      "y\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "eng_w, indic_w = [i for i in train_data[0].__dict__.values()]\n",
    "print(eng_w)\n",
    "for val in eng_w:\n",
    "  print(eng_idx2alpha[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "_9owJfZJMFJq"
   },
   "outputs": [],
   "source": [
    "eng.build_vocab(train_data, max_size = 1000, min_freq = 1)\n",
    "indic.build_vocab(train_data, max_size = 1000, min_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCoDONfrVmPY",
    "outputId": "90a03353-a104-40d2-8a13-863195f84bb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-IuQ5nHu2Ma",
    "outputId": "499f51ac-e47c-430e-b5e0-9a9569cc7153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['freqs', 'itos', 'unk_index', 'stoi', 'vectors'])\n",
      "Help on Vocab in module torchtext.vocab object:\n",
      "\n",
      "class Vocab(builtins.object)\n",
      " |  Vocab(counter, max_size=None, min_freq=1, specials=['<unk>', '<pad>'], vectors=None, unk_init=None, vectors_cache=None, specials_first=True)\n",
      " |  \n",
      " |  Defines a vocabulary object that will be used to numericalize a field.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      freqs: A collections.Counter object holding the frequencies of tokens\n",
      " |          in the data used to build the Vocab.\n",
      " |      stoi: A collections.defaultdict instance mapping token strings to\n",
      " |          numerical identifiers.\n",
      " |      itos: A list of token strings indexed by their numerical identifiers.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getitem__(self, token)\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __init__(self, counter, max_size=None, min_freq=1, specials=['<unk>', '<pad>'], vectors=None, unk_init=None, vectors_cache=None, specials_first=True)\n",
      " |      Create a Vocab object from a collections.Counter.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          counter: collections.Counter object holding the frequencies of\n",
      " |              each value found in the data.\n",
      " |          max_size: The maximum size of the vocabulary, or None for no\n",
      " |              maximum. Default: None.\n",
      " |          min_freq: The minimum frequency needed to include a token in the\n",
      " |              vocabulary. Values less than 1 will be set to 1. Default: 1.\n",
      " |          specials: The list of special tokens (e.g., padding or eos) that\n",
      " |              will be prepended to the vocabulary. Default: ['<unk'>, '<pad>']\n",
      " |          vectors: One of either the available pretrained vectors\n",
      " |              or custom pretrained vectors (see Vocab.load_vectors);\n",
      " |              or a list of aforementioned vectors\n",
      " |          unk_init (callback): by default, initialize out-of-vocabulary word vectors\n",
      " |              to zero vectors; can be any function that takes in a Tensor and\n",
      " |              returns a Tensor of the same size. Default: torch.Tensor.zero_\n",
      " |          vectors_cache: directory for cached vectors. Default: '.vector_cache'\n",
      " |          specials_first: Whether to add special tokens into the vocabulary at first.\n",
      " |              If it is False, they are added into the vocabulary at last.\n",
      " |              Default: True.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  extend(self, v, sort=False)\n",
      " |  \n",
      " |  load_vectors(self, vectors, **kwargs)\n",
      " |      Arguments:\n",
      " |          vectors: one of or a list containing instantiations of the\n",
      " |              GloVe, CharNGram, or Vectors classes. Alternatively, one\n",
      " |              of or a list of available pretrained vectors:\n",
      " |              charngram.100d\n",
      " |              fasttext.en.300d\n",
      " |              fasttext.simple.300d\n",
      " |              glove.42B.300d\n",
      " |              glove.840B.300d\n",
      " |              glove.twitter.27B.25d\n",
      " |              glove.twitter.27B.50d\n",
      " |              glove.twitter.27B.100d\n",
      " |              glove.twitter.27B.200d\n",
      " |              glove.6B.50d\n",
      " |              glove.6B.100d\n",
      " |              glove.6B.200d\n",
      " |              glove.6B.300d\n",
      " |          Remaining keyword arguments: Passed to the constructor of Vectors classes.\n",
      " |  \n",
      " |  set_vectors(self, stoi, vectors, dim, unk_init=<method 'zero_' of 'torch._C._TensorBase' objects>)\n",
      " |      Set the vectors for the Vocab instance from a collection of Tensors.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          stoi: A dictionary of string to the index of the associated vector\n",
      " |              in the `vectors` input argument.\n",
      " |          vectors: An indexed iterable (or other structure supporting __getitem__) that\n",
      " |              given an input index, returns a FloatTensor representing the vector\n",
      " |              for the token associated with the index. For example,\n",
      " |              vector[stoi[\"string\"]] should return the vector for \"string\".\n",
      " |          dim: The dimensionality of the vectors.\n",
      " |          unk_init (callback): by default, initialize out-of-vocabulary word vectors\n",
      " |              to zero vectors; can be any function that takes in a Tensor and\n",
      " |              returns a Tensor of the same size. Default: torch.Tensor.zero_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  UNK = '<unk>'\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(eng.vocab.__dict__.keys())\n",
    "# print(eng.vocab.help?)\n",
    "print(help(eng.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDioMDH6uwsD",
    "outputId": "27379fcc-a8b1-4a5e-aeb7-e509859c8ea0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indic.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1eIGdzqM_19"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYavrckKOFnP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZ0JmGBrS5w2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vX48JEqWa9hT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qH7x5hi7WLbt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxflZSfc4404"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pO0fT8luWIx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ro41iDr3aGOj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xoef1Hz-uMWC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yt4UH821bmoq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKIhfQ0-t1ZI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lsXCA5mb3v-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ-J3aIm7SPK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQAlqawP7PJ_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "9p1Gf44P7EWQ"
   },
   "outputs": [],
   "source": [
    "# indic_langs = sorted([indic_lang for indic_lang in os.listdir(\"aksharantar_sampled\") if indic_lang != '.DS_Store'])\n",
    "# print(indic_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "dGRPlmpl7ELU"
   },
   "outputs": [],
   "source": [
    "# class TransLit_DataLoader(Dataset):\n",
    "#   def __init__(self, filename):\n",
    "#     self.eng_lang_words, self.indic_lang_words = self.readDataset(filename)\n",
    "#     self.shuffle_indices = list(range(len(self.eng_lang_words)))\n",
    "#     random.shuffle(self.shuffle_indices)\n",
    "#     self.shuffle_start_index = 0\n",
    "\n",
    "#   def __len__(self):\n",
    "#     return len(self.eng_lang_words)\n",
    "\n",
    "#   def __getitem__(self, idx):\n",
    "#     return self.eng_lang_words[idx], self.indic_lang_words[idx]\n",
    "\n",
    "#   def readDataset(self, filename):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     # data = []\n",
    "\n",
    "#     with open(filename, 'r') as f:\n",
    "#       for line in f:\n",
    "#         line = line.split(',')\n",
    "#         eng_word = line[0].strip()\n",
    "#         indic_word = line[1].strip()\n",
    "#         X.append(eng_word)\n",
    "#         y.append(indic_word)\n",
    "#         # data_train.append((eng_word, indic_word))\n",
    "#     return X, y\n",
    "\n",
    "#   def get_random_sample(self):\n",
    "#     return self.__getitem__(np.random.randint(len(self.eng_lang_words)))\n",
    "\n",
    "#   def get_batch_from_array(self, batch_size, array):\n",
    "#     end = self.shuffle_start_index + batch_size\n",
    "#     batch = []\n",
    "#     if end >= len(self.eng_lang_words):\n",
    "#       batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_lang_words)]]\n",
    "#     return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index:end]]\n",
    "\n",
    "#   def get_batch(self, batch_size, postprocess = True):\n",
    "#     eng_lang_batch = self.get_batch_from_array(batch_size, self.eng_lang_words)\n",
    "#     indic_lang_batch = self.get_batch_from_array(batch_size, self.indic_lang_words)\n",
    "#     self.shuffle_start_index += batch_size + 1\n",
    "\n",
    "#     # Reshuffle if 1 epoch is complete\n",
    "#     if self.shuffle_start_index >= len(self.eng_lang_words):\n",
    "#       random.shuffle(self.shuffle_indices)\n",
    "#       self.shuffle_start_index = 0\n",
    "\n",
    "#     return eng_lang_batch, indic_lang_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "kn19K4vE60pJ"
   },
   "outputs": [],
   "source": [
    "# data_train = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_train.csv')\n",
    "# data_val = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_valid.csv')\n",
    "# data_test = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "NmKmTPyty7mI"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(net, device = 'cpu', data = val_data):\n",
    "    # net = net.eval().to(device)\n",
    "    # predictions = []\n",
    "    accuracy = 0\n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        eng_word, indic_word = [j for j in data[i].__dict__.values()]\n",
    "        # gt = gt_rep(indic_word, indic_alpha2idx, device)\n",
    "\n",
    "        # outputs = infer(net, eng_word, gt.shape[0], device)\n",
    "        output = translit_infer(net, eng_word, eng, indic, device, max_length=50)\n",
    "        correct = 0\n",
    "\n",
    "        for index, char in output:\n",
    "          if char == indic_word[index]:\n",
    "            correct += 1\n",
    "\n",
    "\n",
    "        char_level_acc = correct/len(indic_word)\n",
    "        \n",
    "        if char_level_acc == 1.0:\n",
    "          count += 1\n",
    "    print(count)\n",
    "    accuracy = count/len(data)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "8qyO9m_DcJAW"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True, dropout=p)\n",
    "\n",
    "        # Linear Layer takes the two hidden states from Bidirectional RNN and outputs a single hidden state with weights learnt by network\n",
    "        self.fc_hidden = nn.Linear(hidden_size*2, hidden_size)\n",
    "        # Same for cell/state\n",
    "        self.fc_cell = nn.Linear(hidden_size*2, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "#         print(encoder_states.shape, hidden[0].shape, cell.shape)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        # First Value for forward dir, scond value for forward dir\n",
    "        #hidden shape: (2, N, hidden_size)\n",
    "#         encoder_states = self.fc_hidden(torch.cat((encoder_states[0:1], encoder_states[1:2]), dim=2))\n",
    "#         print(hidden.shape)\n",
    "        #hidden shape: (1, N, hidden_size)\n",
    "#         cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "\n",
    "        # extra dimension due to bidirectional - one going forward, one going backward\n",
    "        \n",
    "        # Now for attention, we would need all the encoder_states to add attention, but the hidden one is just the final encoded output\n",
    "        return encoder_states, hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        # hidden_size*2 comes from the encoder\n",
    "        self.rnn = nn.LSTM(hidden_size*2 + embedding_size, hidden_size, num_layers, dropout=p)\n",
    "\n",
    "        # We would take the hidden states from the encoder, but we would also take the hidden state from the decoder (s(t-1), h(j))\n",
    "        self.energy = nn.Linear(hidden_size*2, 1)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "\n",
    "        # To add them together, we need to have the same dim along that axis\n",
    "#         h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "\n",
    "        # h_reshape -> (hidden_size), encoder_states -> (hidden_size*2)\n",
    "#         energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim = 2)))\n",
    "        energy = self.relu(self.energy(encoder_states))\n",
    "\n",
    "        # Compute attention values\n",
    "        attention = self.softmax(energy)\n",
    "        # (seq_length, N, 1) -> We'll normalize through the first dim - seq_length so that sum of attention scores equals 1 for a specific batch\n",
    "\n",
    "        # Goal is to elementwise multiply attention with the encoder state\n",
    "        attention = attention.permute(1,2,0) #-> changing order to (N,seq_length,1)\n",
    "        encoder_states = encoder_states.permute(1,0,2) #-> changer order to (N, seq_length, hidden_size*2)\n",
    "\n",
    "        # Multiplying the above by torch.bmm we'll get: (N, 1, hidden_size*2) -> permuting it -> (1,N, hidden_size*2)\n",
    "        context_vector = torch.bmm(attention, encoder_states).permute(1,0,2)\n",
    "\n",
    "        #context_vector is for a particular timestep for decoder, since decoding one word at a time\n",
    "        # we'll concat along 3rd dim to get hidden_size*3 -> concatenating attention vector and embedding input\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "\n",
    "        #Send this through RNN\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(indic.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            print(hidden.shape, cell.shape)\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "NJBBW4u3zwae"
   },
   "outputs": [],
   "source": [
    "\n",
    "def translit_infer(model, word, eng, indic, device, max_length=50):\n",
    "    tokens = tokenize_eng(word)\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, eng.init_token)\n",
    "    tokens.append(eng.eos_token)\n",
    "\n",
    "\n",
    "    text_to_indices = [eng.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    word_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        encoder_states, hidden, cell = model.encoder(word_tensor)\n",
    "\n",
    "    outputs = [indic.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_char = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(previous_char, encoder_states, hidden, cell)\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == indic.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translit_res = [indic.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    translit_res_word = ''\n",
    "    translit_res = translit_res[1:]\n",
    "    # return translit_res\n",
    "    for i in translit_res:\n",
    "      if i != \"<eos>\":\n",
    "        translit_res_word += indic_idx2alpha[i]\n",
    "      else:\n",
    "        break\n",
    "    return translit_res_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "8yUgp84Mz3t_"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=f\"{indic_lang}_2_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "EHVn3O5_ITh8"
   },
   "outputs": [],
   "source": [
    "from IPython.utils.path import target_outdated\n",
    "def check_accuracy(loader, model, input_shape=None, toggle_eval=True, print_accuracy=True):\n",
    "    if toggle_eval:\n",
    "        model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loader.create_batches()\n",
    "        for batch in loader.batches:\n",
    "          for example in batch:\n",
    "            num_samples += 1\n",
    "            eng_word = \"\".join([eng_idx2alpha[val] for val in example.eng])\n",
    "            indic_word = \"\".join([indic_idx2alpha[val2] for val2 in example.indic])\n",
    "            indic_pred = translit_infer(model, eng_word, eng, indic, device, max_length=50)\n",
    "            \n",
    "            if indic_pred == indic_word:\n",
    "              num_correct += 1\n",
    "\n",
    "    accuracy = num_correct / num_samples\n",
    "    if toggle_eval:\n",
    "        model.train()\n",
    "#     if print_accuracy:\n",
    "#         print(f\"Accuracy on validation set: {accuracy * 100:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "FqtOKyDGm7Oh"
   },
   "outputs": [],
   "source": [
    "### Now model is ready to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 µs, sys: 0 ns, total: 52 µs\n",
      "Wall time: 57.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training Hyperparameters\n",
    "num_epochs =30\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "# Model Hyperparameters\n",
    "load_model = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size_encoder = len(eng.vocab)\n",
    "input_size_decoder = len(indic.vocab)\n",
    "output_size = len(indic.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rggL-b4Mm-4w",
    "outputId": "5a7efc42-11f3-439c-acce-d46325f33dee"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    train_iterator, val_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data),\n",
    "    batch_size = batch_size,\n",
    "    # Examples of similar length will be in same batch to minimize padding and save on compute\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.eng),\n",
    "    device = device)\n",
    "\n",
    "\n",
    "\n",
    "    encoder_net = Encoder(\n",
    "        input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    "        ).to(device)\n",
    "    decoder_net = Decoder(\n",
    "        input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout\n",
    "        ).to(device)\n",
    "\n",
    "    model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    pad_idx = indic.vocab.stoi['<pad>']\n",
    "    # if all examples in batch are of similar length, don't incur penalty for this padding\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n",
    "\n",
    "    if load_model:\n",
    "      load_checkpoint(torch.load(f'{indic_lang}_checkpoint.pth.tar'), model, optimizer)\n",
    "\n",
    "    word = 'bachta'\n",
    "    og_translit = 'बचता'\n",
    "    acc_val_prev = 0\n",
    "    acc_val_current = 0\n",
    "    for epoch in range(num_epochs):\n",
    "      print(f'Epoch [{epoch+1} / {num_epochs}]')\n",
    "\n",
    "      checkpoint = {\n",
    "          'state_dict': model.state_dict(),\n",
    "          'optimizer': optimizer.state_dict()\n",
    "      }\n",
    "      if acc_val_current > acc_val_prev:\n",
    "\n",
    "          if os.path.exists(f'{indic_lang}_checkpoint_new_{acc_val_prev*100:.2f}.pth.tar'):\n",
    "              os.remove(f'{indic_lang}_checkpoint_new_{acc_val_prev*100:.2f}.pth.tar')\n",
    "          acc_val_prev = acc_val_current\n",
    "          save_checkpoint(checkpoint, f'{indic_lang}_checkpoint_new_{acc_val_current*100:.2f}.pth.tar')\n",
    "\n",
    "\n",
    "\n",
    "      loop = tqdm(enumerate(train_iterator), total=len(train_iterator))\n",
    "      for batch_idx, batch in loop:\n",
    "        inp_data = batch.eng.to(device)\n",
    "        target = batch.indic.to(device)\n",
    "\n",
    "        output = model(inp_data, target)\n",
    "        # output shape: (target_len, batch_size, output_dim)\n",
    "\n",
    "        #basically reshape output keeping last output_dim same\n",
    "        output = output[1:].reshape(-1, output.shape[2]) # so that first start token is not sent to out model\n",
    "        # target -> (target_len, batch_size)\n",
    "        target = target[1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # to avoid exploding gradients, clip them when they are above a threshold\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "\n",
    "      model.eval() # turns off Dropout\n",
    "      translit_res = translit_infer(model, word, eng, indic, device, max_length=50)\n",
    "      print(f'Translated example word:  English: {word}, Actual: {og_translit}, Predicted: {translit_res}')\n",
    "      model.train()\n",
    "\n",
    "      print('Computing Loss and Validation Accuracy...')\n",
    "      acc_val_current = check_accuracy(val_iterator, model, input_shape=None, toggle_eval=True, print_accuracy=True)\n",
    "      print(f'Training Loss: {loss.item()}, Validation Accuracy: {acc_val_current * 100:.2f}%')\n",
    "      print('--------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czpOpuQZs4Qk",
    "outputId": "22026b02-42f7-43f6-88b9-2bafe5876a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 512]) torch.Size([4, 64, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 64, 512), got [4, 64, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [186]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m inp_data \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39meng\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     53\u001b[0m target \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mindic\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 55\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# output shape: (target_len, batch_size, output_dim)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#basically reshape output keeping last output_dim same\u001b[39;00m\n\u001b[1;32m     59\u001b[0m output \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m# so that first start token is not sent to out model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [180]\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, source, target, teacher_force_ratio)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, target_len):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# Use previous hidden, cell as context from encoder at start\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mprint\u001b[39m(hidden\u001b[38;5;241m.\u001b[39mshape, cell\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 126\u001b[0m     output, hidden, cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Store next output prediction\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     outputs[t] \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [180]\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, encoder_states, hidden, cell)\u001b[0m\n\u001b[1;32m     89\u001b[0m rnn_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((context_vector, embedding), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#Send this through RNN\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m outputs, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# outputs shape: (1, N, hidden_size)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:810\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:731\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    726\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    727\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    728\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    729\u001b[0m                        ):\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_expected_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpected hidden[0] size \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, got \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    734\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    237\u001b[0m                       msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 64, 512), got [4, 64, 512]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "id": "cGwkS7zD8SI2",
    "outputId": "af0712c3-3148-4a4c-f179-4a08002f3ec7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwv-ssKrJnft"
   },
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(val_iterator):\n",
    "    inp_data = batch.eng\n",
    "    target = batch.indic\n",
    "    print(inp_data.shape, target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42xgSCQ_J8-i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
