{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oikn2018/CS6910_assignment_3/blob/main/sweep_w_att.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KreNpqQWnde",
        "outputId": "9b7a78cd-e702-43f7-c0b3-16d711e7f0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0\n",
        "# import locale\n",
        "# locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "! pip install wget\n",
        "! pip install gdown\n",
        "! pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wandb\n",
        "# ! wandb login 519ef73bbeeba4f437e82d8aeb9cf27e62a84740"
      ],
      "metadata": {
        "id": "87vvJG0Pro7B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wYmZkdTHV1gb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import gdown\n",
        "from tqdm import tqdm\n",
        "# import wandb\n",
        "from io import open\n",
        "import string, time, math\n",
        "import wget\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.data import Dataset\n",
        "import re\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "# import numpy as np\n",
        "import spacy\n",
        "# import random\n",
        "# from torch.utils.tensorboard import SummaryWriter # to print to tensorboard\n",
        "# from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gaw2m7L5Dj0j"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "# CUDA\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic=True\n",
        "torch.backends.cudnn.benchmark=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q87jZlq8D--z"
      },
      "outputs": [],
      "source": [
        "# Getting the Dataset\n",
        "url = 'https://drive.google.com/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download'\n",
        "\n",
        "if not os.path.exists(\"aksharantar_sampled\"):\n",
        "  filename = gdown.download(url = url, quiet=False, fuzzy=True)\n",
        "  print(filename)\n",
        "  with ZipFile(filename, 'r') as z:\n",
        "    print('Extracting files...')\n",
        "    z.extractall()\n",
        "    print('Done!')\n",
        "  os.remove(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L1cP5vkMgOD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f2a8fe-e1aa-475d-939b-3e5dcdd9773b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<PAD>': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
          ]
        }
      ],
      "source": [
        "eng_alpha = 'abcdefghijklmnopqrstuvwxyz'\n",
        "pad_char = '<PAD>'\n",
        "\n",
        "eng_alpha2idx = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alpha):\n",
        "  eng_alpha2idx[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change Indic Language here\n",
        "indic_lang = 'ben'\n",
        "# indic_lang = 'hin'"
      ],
      "metadata": {
        "id": "O_Jxy7gDr4RX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "beH3ItF4gTTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6340234e-202a-46fc-88f3-ede00bfb753b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ঀ', 'ঁ', 'ং', 'ঃ', '\\u0984', 'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'ঌ', '\\u098d', '\\u098e', 'এ', 'ঐ', '\\u0991', '\\u0992', 'ও', 'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', '\\u09a9', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', '\\u09b1', 'ল', '\\u09b3', '\\u09b4', '\\u09b5', 'শ', 'ষ', 'স', 'হ', '\\u09ba', '\\u09bb', '়', 'ঽ', 'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ৄ', '\\u09c5', '\\u09c6', 'ে', 'ৈ', '\\u09c9', '\\u09ca', 'ো', 'ৌ', '্', 'ৎ', '\\u09cf', '\\u09d0', '\\u09d1', '\\u09d2', '\\u09d3', '\\u09d4', '\\u09d5', '\\u09d6', 'ৗ', '\\u09d8', '\\u09d9', '\\u09da', '\\u09db', 'ড়', 'ঢ়', '\\u09de', 'য়', 'ৠ', 'ৡ', 'ৢ', 'ৣ', '\\u09e4', '\\u09e5', '০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯', 'ৰ', 'ৱ', '৲', '৳', '৴', '৵', '৶', '৷', '৸', '৹', '৺', '৻', 'ৼ', '৽', '৾']\n",
            "{'<PAD>': 0, 'ঀ': 1, 'ঁ': 2, 'ং': 3, 'ঃ': 4, '\\u0984': 5, 'অ': 6, 'আ': 7, 'ই': 8, 'ঈ': 9, 'উ': 10, 'ঊ': 11, 'ঋ': 12, 'ঌ': 13, '\\u098d': 14, '\\u098e': 15, 'এ': 16, 'ঐ': 17, '\\u0991': 18, '\\u0992': 19, 'ও': 20, 'ঔ': 21, 'ক': 22, 'খ': 23, 'গ': 24, 'ঘ': 25, 'ঙ': 26, 'চ': 27, 'ছ': 28, 'জ': 29, 'ঝ': 30, 'ঞ': 31, 'ট': 32, 'ঠ': 33, 'ড': 34, 'ঢ': 35, 'ণ': 36, 'ত': 37, 'থ': 38, 'দ': 39, 'ধ': 40, 'ন': 41, '\\u09a9': 42, 'প': 43, 'ফ': 44, 'ব': 45, 'ভ': 46, 'ম': 47, 'য': 48, 'র': 49, '\\u09b1': 50, 'ল': 51, '\\u09b3': 52, '\\u09b4': 53, '\\u09b5': 54, 'শ': 55, 'ষ': 56, 'স': 57, 'হ': 58, '\\u09ba': 59, '\\u09bb': 60, '়': 61, 'ঽ': 62, 'া': 63, 'ি': 64, 'ী': 65, 'ু': 66, 'ূ': 67, 'ৃ': 68, 'ৄ': 69, '\\u09c5': 70, '\\u09c6': 71, 'ে': 72, 'ৈ': 73, '\\u09c9': 74, '\\u09ca': 75, 'ো': 76, 'ৌ': 77, '্': 78, 'ৎ': 79, '\\u09cf': 80, '\\u09d0': 81, '\\u09d1': 82, '\\u09d2': 83, '\\u09d3': 84, '\\u09d4': 85, '\\u09d5': 86, '\\u09d6': 87, 'ৗ': 88, '\\u09d8': 89, '\\u09d9': 90, '\\u09da': 91, '\\u09db': 92, 'ড়': 93, 'ঢ়': 94, '\\u09de': 95, 'য়': 96, 'ৠ': 97, 'ৡ': 98, 'ৢ': 99, 'ৣ': 100, '\\u09e4': 101, '\\u09e5': 102, '০': 103, '১': 104, '২': 105, '৩': 106, '৪': 107, '৫': 108, '৬': 109, '৭': 110, '৮': 111, '৯': 112, 'ৰ': 113, 'ৱ': 114, '৲': 115, '৳': 116, '৴': 117, '৵': 118, '৶': 119, '৷': 120, '৸': 121, '৹': 122, '৺': 123, '৻': 124, 'ৼ': 125, '৽': 126, '৾': 127}\n"
          ]
        }
      ],
      "source": [
        "# Bengali Unicode Hex Range: 2432-2558\n",
        "# Hindi Unicode Hex Range: 2304-2431\n",
        "\n",
        "min_range = 2304\n",
        "max_range = 2431\n",
        "\n",
        "if indic_lang == 'ben':\n",
        "  min_range = 2432\n",
        "  max_range = 2558\n",
        "elif indic_lang == 'hin':\n",
        "  min_range = 2304\n",
        "  max_range = 2431\n",
        "\n",
        "indic_alpha = [chr(alpha) for alpha in range(min_range, max_range + 1)]\n",
        "print(indic_alpha)\n",
        "indic_alpha_size = len(indic_alpha)\n",
        "\n",
        "indic_alpha2idx = {pad_char: 0}\n",
        "for index, alpha in enumerate(indic_alpha):\n",
        "  indic_alpha2idx[alpha] = index+1\n",
        "\n",
        "print(indic_alpha2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tNrcqaQQ6j-5"
      },
      "outputs": [],
      "source": [
        "indic_idx2alpha = {v: k for k, v in indic_alpha2idx.items()}\n",
        "eng_idx2alpha = {v: k for k, v in eng_alpha2idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3j6vZGlyEuKo"
      },
      "outputs": [],
      "source": [
        "def tokenize_indic(string):\n",
        "  # return string.split()\n",
        "  char_list =  [*string]\n",
        "  char_list = [indic_alpha2idx[char] for char in char_list]\n",
        "  return char_list\n",
        "\n",
        "def tokenize_eng(string):\n",
        "  # return string.split()\n",
        "  char_list =  [*string]\n",
        "  char_list = [eng_alpha2idx[char] for char in char_list]\n",
        "  return char_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FCuwdH7VHXE1"
      },
      "outputs": [],
      "source": [
        "# importing python package\n",
        "import pandas as pd\n",
        "  \n",
        "file_names = ['test', 'train', 'valid']\n",
        "\n",
        "for index, file_name in enumerate(file_names):\n",
        "  # read contents of csv file\n",
        "  file = pd.read_csv(f'aksharantar_sampled/{indic_lang}/{indic_lang}_{file_name}.csv')\n",
        "    \n",
        "  # adding header\n",
        "  headerList = ['eng', f'{indic_lang}']\n",
        "    \n",
        "  # converting data frame to csv\n",
        "  file.to_csv(f'aksharantar_sampled/{indic_lang}/{indic_lang}_{file_name}.csv', header=headerList, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gUYK7Us1EDqD"
      },
      "outputs": [],
      "source": [
        "eng = Field(sequential=True, use_vocab=True, tokenize=tokenize_eng, init_token='<sos>', eos_token='<eos>')\n",
        "indic = Field(sequential=True, use_vocab=True, tokenize=tokenize_indic, init_token='<sos>', eos_token='<eos>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5RFKlw5MEx6l"
      },
      "outputs": [],
      "source": [
        "fields={'eng': ('eng', eng), f'{indic_lang}': ('indic', indic)}\n",
        "\n",
        "path_name = f'aksharantar_sampled/{indic_lang}'\n",
        "train_name = f'{indic_lang}_train.csv'\n",
        "val_name = f'{indic_lang}_valid.csv'\n",
        "test_name = f'{indic_lang}_test.csv'\n",
        "train_data, val_data, test_data = TabularDataset.splits(\n",
        "    path= path_name,\n",
        "    train=train_name,\n",
        "    validation=val_name,\n",
        "    test=test_name,\n",
        "    format='csv',\n",
        "    fields=fields\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AwT-AtD0MaKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8105c3b0-6b07-4ccd-a904-16e0fb4c93d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['eng', 'indic'])\n"
          ]
        }
      ],
      "source": [
        "print(train_data[0].__dict__.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SIaEB78IKrdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a89dbc-cc6b-47d1-cd2d-27468bbd67bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([[8, 9, 14, 4, 21, 11, 21, 19, 8, 5, 18], [58, 64, 41, 78, 39, 66, 22, 66, 55, 72, 49]])\n"
          ]
        }
      ],
      "source": [
        "print(train_data[0].__dict__.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_9owJfZJMFJq"
      },
      "outputs": [],
      "source": [
        "eng.build_vocab(train_data, max_size = 1000, min_freq = 1)\n",
        "indic.build_vocab(train_data, max_size = 1000, min_freq = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NmKmTPyty7mI"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(net, device = 'cpu', data = val_data):\n",
        "    # net = net.eval().to(device)\n",
        "    # predictions = []\n",
        "    accuracy = 0\n",
        "    count = 0\n",
        "    for i in range(len(data)):\n",
        "        eng_word, indic_word = [j for j in data[i].__dict__.values()]\n",
        "        # gt = gt_rep(indic_word, indic_alpha2idx, device)\n",
        "\n",
        "        # outputs = infer(net, eng_word, gt.shape[0], device)\n",
        "        output = translit_infer(net, eng_word, eng, indic, device, max_length=50)\n",
        "        correct = 0\n",
        "\n",
        "        for index, char in output:\n",
        "          if char == indic_word[index]:\n",
        "            correct += 1\n",
        "\n",
        "\n",
        "        char_level_acc = correct/len(indic_word)\n",
        "        \n",
        "        if char_level_acc == 1.0:\n",
        "          count += 1\n",
        "    # print(count)\n",
        "    accuracy = count/len(data)\n",
        "    \n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NJBBW4u3zwae"
      },
      "outputs": [],
      "source": [
        "def translit_infer(model, word, eng, indic, device, max_length=50):\n",
        "    tokens = tokenize_eng(word)\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, eng.init_token)\n",
        "    tokens.append(eng.eos_token)\n",
        "\n",
        "\n",
        "    text_to_indices = [eng.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    word_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        encoder_states, hidden, cell = model.encoder(word_tensor)\n",
        "\n",
        "    outputs = [indic.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_char = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(previous_char, encoder_states, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == indic.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translit_res = [indic.vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "    # remove start token\n",
        "    translit_res_word = ''\n",
        "    translit_res = translit_res[1:]\n",
        "    # return translit_res\n",
        "    for i in translit_res:\n",
        "      if i != \"<eos>\":\n",
        "        translit_res_word += indic_idx2alpha[i]\n",
        "      else:\n",
        "        break\n",
        "    return translit_res_word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8yUgp84Mz3t_"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, filename=f\"{indic_lang}_2_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EHVn3O5_ITh8"
      },
      "outputs": [],
      "source": [
        "from IPython.utils.path import target_outdated\n",
        "def check_accuracy(loader, model, input_shape=None, toggle_eval=True, print_accuracy=True):\n",
        "    if toggle_eval:\n",
        "        model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loader.create_batches()\n",
        "        for batch in loader.batches:\n",
        "          for example in batch:\n",
        "            num_samples += 1\n",
        "            eng_word = \"\".join([eng_idx2alpha[val] for val in example.eng])\n",
        "            indic_word = \"\".join([indic_idx2alpha[val2] for val2 in example.indic])\n",
        "            indic_pred = translit_infer(model, eng_word, eng, indic, device, max_length=50)\n",
        "            \n",
        "            if indic_pred == indic_word:\n",
        "              num_correct += 1\n",
        "\n",
        "    accuracy = num_correct / num_samples\n",
        "    if toggle_eval:\n",
        "        model.train()\n",
        "#     if print_accuracy:\n",
        "#         print(f\"Accuracy on validation set: {accuracy * 100:.2f}%\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8qyO9m_DcJAW"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embedding layer to convert input tokens to vectors\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        # LSTM layer for encoding the input sequence\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True, dropout=p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "        # Pass the embedded input through the LSTM\n",
        "        # encoder_states: outputs of LSTM for each timestep\n",
        "        # hidden: hidden states for the last timestep\n",
        "        # cell: cell states for the last timestep\n",
        "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
        "        # print(hidden.shape)\n",
        "        # Compute the average of the hidden and cell states for bidirectional LSTM\n",
        "        hidden = (hidden[0:self.num_layers] + hidden[self.num_layers:2*self.num_layers]) / 2\n",
        "        cell = (cell[0:self.num_layers] + cell[self.num_layers:2*self.num_layers]) / 2\n",
        "        # print(f'E,H,C -> {encoder_states.shape}, {hidden.shape}, {cell.shape}')\n",
        "        return encoder_states, hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embedding layer to convert input tokens to vectors\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        # LSTM layer for decoding the output sequence\n",
        "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers, dropout=p)\n",
        "\n",
        "        # Linear layer to calculate attention scores\n",
        "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Linear layer for final output prediction\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, encoder_states, hidden, cell):\n",
        "        # x: (1, N) where N is the batch size\n",
        "        x = x.unsqueeze(0)\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "        sequence_length = encoder_states.shape[0]\n",
        "        # Implementation Logic 1: taking final layer hidden tensor value and passing it onto energy.\n",
        "        # hidden_temp = hidden[-1].unsqueeze(0)\n",
        "        # Implementation Logic 2: taking average of all layer hidden tensor values and passing it onto energy.\n",
        "        hidden_temp = torch.mean(hidden, dim=0).unsqueeze(0)\n",
        "\n",
        "        # Expand the hidden states to match the sequence length\n",
        "        h_reshaped = hidden_temp.repeat(sequence_length, 1, 1)\n",
        "        # h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
        "        # print(h_reshaped.shape, sequence_length, hidden.shape, encoder_states.shape)\n",
        "        # Calculate energy scores for attention\n",
        "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
        "\n",
        "        # Compute attention values\n",
        "        attention = self.softmax(energy)\n",
        "        # Calculate the context vector using attention\n",
        "        context_vector = torch.bmm(attention.permute(1, 2, 0), encoder_states.permute(1, 0, 2)).permute(1,0,2)\n",
        "\n",
        "        # Concatenate the context vector and embedded input\n",
        "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
        "\n",
        "        # Pass the concatenated input through the LSTM\n",
        "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "        # Final output prediction\n",
        "        predictions = self.fc(outputs)\n",
        "\n",
        "        # Remove the first dimension to match the target shape\n",
        "        predictions = predictions.squeeze(0)\n",
        "\n",
        "        return predictions, hidden, cell\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        batch_size = source.shape[1]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = len(indic.vocab)\n",
        "\n",
        "        # Initialize tensor to store decoder outputs\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "        # Pass the source sequence through the encoder\n",
        "        encoder_states, hidden, cell = self.encoder(source)\n",
        "\n",
        "        # # Initialize decoder hidden and cell states with the final states of the encoder\n",
        "        # decoder_hidden = encoder_hidden.view(self.encoder.num_layers, 2, batch_size, -1).transpose(1, 2).contiguous()\n",
        "        # decoder_cell = encoder_cell.view(self.encoder.num_layers, 2, batch_size, -1).transpose(1, 2).contiguous()\n",
        "\n",
        "        # Grab the first input to the Decoder which will be the start token\n",
        "        x = target[0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            # Pass the input, encoder states, and decoder states through the decoder\n",
        "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            # Determine the next input to the decoder based on teacher forcing ratio\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EzVm5W-0qfrN"
      },
      "outputs": [],
      "source": [
        "# Training Hyperparameters\n",
        "num_epochs =5\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "\n",
        "# Model Hyperparameters\n",
        "load_model = False\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "input_size_encoder = len(eng.vocab)\n",
        "input_size_decoder = len(indic.vocab)\n",
        "output_size = len(indic.vocab)\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 512\n",
        "num_layers = 3\n",
        "enc_dropout = 0.5\n",
        "dec_dropout = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rggL-b4Mm-4w"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    \n",
        "    train_iterator, val_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    batch_size = batch_size,\n",
        "    # Examples of similar length will be in same batch to minimize padding and save on compute\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.eng),\n",
        "    device = device)\n",
        "\n",
        "\n",
        "\n",
        "    encoder_net = Encoder(\n",
        "        input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
        "        ).to(device)\n",
        "    decoder_net = Decoder(\n",
        "        input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout\n",
        "        ).to(device)\n",
        "\n",
        "    model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    pad_idx = indic.vocab.stoi['<pad>']\n",
        "    # if all examples in batch are of similar length, don't incur penalty for this padding\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n",
        "\n",
        "    if load_model:\n",
        "      load_checkpoint(torch.load(f'{indic_lang}_checkpoint.pth.tar'), model, optimizer)\n",
        "    if indic_lang == 'hin':\n",
        "      word = 'bachta'\n",
        "      og_translit = 'बचता'\n",
        "    elif indic_lang == 'ben':\n",
        "      word = 'gabhaaskar'\n",
        "      og_translit = 'গাভাস্কার'\n",
        "    acc_val_prev = 0\n",
        "    acc_val_current = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      print(f'Epoch [{epoch+1} / {num_epochs}]')\n",
        "\n",
        "      checkpoint = {\n",
        "          'state_dict': model.state_dict(),\n",
        "          'optimizer': optimizer.state_dict()\n",
        "      }\n",
        "      if acc_val_current > acc_val_prev:\n",
        "\n",
        "          if os.path.exists(f'{indic_lang}_checkpoint_new_{acc_val_prev*100:.2f}.pth.tar'):\n",
        "              os.remove(f'{indic_lang}_checkpoint_new_{acc_val_prev*100:.2f}.pth.tar')\n",
        "          acc_val_prev = acc_val_current\n",
        "          save_checkpoint(checkpoint, f'{indic_lang}_checkpoint_new_{acc_val_current*100:.2f}.pth.tar')\n",
        "\n",
        "\n",
        "\n",
        "      loop = tqdm(enumerate(train_iterator), total=len(train_iterator))\n",
        "      for batch_idx, batch in loop:\n",
        "        inp_data = batch.eng.to(device)\n",
        "        target = batch.indic.to(device)\n",
        "\n",
        "        output = model(inp_data, target)\n",
        "        # break\n",
        "        # output shape: (target_len, batch_size, output_dim)\n",
        "\n",
        "        #basically reshape output keeping last output_dim same\n",
        "        output = output[1:].reshape(-1, output.shape[2]) # so that first start token is not sent to out model\n",
        "        # target -> (target_len, batch_size)\n",
        "        target = target[1:].reshape(-1)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # to avoid exploding gradients, clip them when they are above a threshold\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "      model.eval() # turns off Dropout\n",
        "      translit_res = translit_infer(model, word, eng, indic, device, max_length=50)\n",
        "      print(f'Translated example word:  English: {word}, Actual: {og_translit}, Predicted: {translit_res}')\n",
        "      model.train()\n",
        "      epoch_loss = epoch_loss/len(train_iterator)\n",
        "      print('Computing Loss and Validation Accuracy...')\n",
        "      acc_val_current = check_accuracy(val_iterator, model, input_shape=None, toggle_eval=True, print_accuracy=True)\n",
        "      # print(f'Training Loss: {loss.item()}, Validation Accuracy: {acc_val_current * 100:.2f}%')\n",
        "      print(f'Training Loss: {epoch_loss:.3f}, Validation Accuracy: {acc_val_current * 100:.2f}%')\n",
        "      print('--------------------------')\n",
        "      epoch_loss = 0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czpOpuQZs4Qk",
        "outputId": "dd350ffa-10e4-428d-a040-c35a494a00d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:52<00:00, 15.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated example word:  English: gabhaaskar, Actual: গাভাস্কার, Predicted: গভাসাকার\n",
            "Computing Loss and Validation Accuracy...\n",
            "Training Loss: 1.752, Validation Accuracy: 15.46%\n",
            "--------------------------\n",
            "Epoch [2 / 5]\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:51<00:00, 15.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated example word:  English: gabhaaskar, Actual: গাভাস্কার, Predicted: গভাসসকার\n",
            "Computing Loss and Validation Accuracy...\n",
            "Training Loss: 0.876, Validation Accuracy: 24.54%\n",
            "--------------------------\n",
            "Epoch [3 / 5]\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:51<00:00, 15.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated example word:  English: gabhaaskar, Actual: গাভাস্কার, Predicted: গভাসক্র\n",
            "Computing Loss and Validation Accuracy...\n",
            "Training Loss: 0.685, Validation Accuracy: 29.47%\n",
            "--------------------------\n",
            "Epoch [4 / 5]\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:51<00:00, 15.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated example word:  English: gabhaaskar, Actual: গাভাস্কার, Predicted: গভভস্কর\n",
            "Computing Loss and Validation Accuracy...\n",
            "Training Loss: 0.599, Validation Accuracy: 32.11%\n",
            "--------------------------\n",
            "Epoch [5 / 5]\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:51<00:00, 15.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated example word:  English: gabhaaskar, Actual: গাভাস্কার, Predicted: গভভস্কর\n",
            "Computing Loss and Validation Accuracy...\n",
            "Training Loss: 0.529, Validation Accuracy: 32.94%\n",
            "--------------------------\n",
            "CPU times: user 7min 11s, sys: 3.04 s, total: 7min 14s\n",
            "Wall time: 7min 33s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uORgcL9KM2n_"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}