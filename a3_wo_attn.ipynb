{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oikn2018/CS6910_assignment_3/blob/main/a3_wo_attn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Commands\n",
        "! pip install wget\n",
        "! pip install gdown\n",
        "! pip install --upgrade gdown\n",
        "# ! pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR290vFmOUDY",
        "outputId": "b42e1efb-48c6-44e7-d860-7cafd15a7eba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9676 sha256=0b8004d1f667b7577503de1cce405ede4e71025f2a6f5c96d7457a45dcf46e7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import gdown\n",
        "# import wandb\n",
        "from io import open\n",
        "import string, time, math\n",
        "import wget\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.data import Dataset\n",
        "import re"
      ],
      "metadata": {
        "id": "yPP3T6frM-uq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "# CUDA\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "# torch.backends.cudnn.deterministic=True\n",
        "# torch.backends.cudnn.benchmark=False"
      ],
      "metadata": {
        "id": "QrFxXQDRVD5P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_gpu = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "CNoiOBN5NSoh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the Dataset\n",
        "url = 'https://drive.google.com/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download'\n",
        "# filename = os.path.basename(url)\n",
        "# print(filename)\n",
        "\n",
        "if not os.path.exists(\"aksharantar_sampled\"):\n",
        "  filename = gdown.download(url = url, quiet=False, fuzzy=True)\n",
        "  print(filename)\n",
        "  with ZipFile(filename, 'r') as z:\n",
        "    print('Extracting files...')\n",
        "    z.extractall()\n",
        "    print('Done!')\n",
        "  os.remove(filename)"
      ],
      "metadata": {
        "id": "CqymbOGsQCSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ea1f88-9449-4bb7-a42a-062220dacfdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw\n",
            "To: /content/aksharantar_sampled.zip\n",
            "100%|██████████| 14.0M/14.0M [00:00<00:00, 40.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aksharantar_sampled.zip\n",
            "Extracting files...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_alpha = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '<PAD>'\n",
        "\n",
        "eng_alpha2idx = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alpha):\n",
        "  eng_alpha2idx[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3jjj7_pQphV",
        "outputId": "90cf79c6-ae56-488c-ab09-194c27a484a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<PAD>': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change Indic Language here\n",
        "# indic_lang = 'ben'\n",
        "indic_lang = 'hin'"
      ],
      "metadata": {
        "id": "Ld_X-RaYMzCv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bengali Unicode Hex Range: 2432-2558\n",
        "# Hindi Unicode Hex Range: 2304-2431\n",
        "\n",
        "min_range = 2304\n",
        "max_range = 2431\n",
        "\n",
        "if indic_lang == 'ben':\n",
        "  min_range = 2432\n",
        "  max_range = 2558\n",
        "elif indic_lang == 'hindi':\n",
        "  min_range = 2304\n",
        "  max_range = 2431\n",
        "\n",
        "indic_alpha = [chr(alpha) for alpha in range(min_range, max_range + 1)]\n",
        "print(indic_alpha)\n",
        "indic_alpha_size = len(indic_alpha)\n",
        "\n",
        "indic_alpha2idx = {pad_char: 0}\n",
        "for index, alpha in enumerate(indic_alpha):\n",
        "  indic_alpha2idx[alpha] = index+1\n",
        "\n",
        "print(indic_alpha2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0PjyADuTfHv",
        "outputId": "8efa86fa-2ea9-4eaa-9303-9f7fab2c4ba8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ', 'ॿ']\n",
            "{'<PAD>': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indic_langs = sorted([indic_lang for indic_lang in os.listdir(\"aksharantar_sampled\") if indic_lang != '.DS_Store'])\n",
        "print(indic_langs)"
      ],
      "metadata": {
        "id": "RqbEtORMbreO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ec7a9a-ee28-4dad-d042-1a2f8bd0c598"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['asm', 'ben', 'brx', 'guj', 'hin', 'kan', 'kas', 'kok', 'mai', 'mal', 'mar', 'mni', 'ori', 'pan', 'san', 'sid', 'tam', 'tel', 'urd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = []\n",
        "# y_train = []\n",
        "# data_train = []\n",
        "\n",
        "# X_val = []\n",
        "# y_val = []\n",
        "# data_val = []\n",
        "\n",
        "# X_test = []\n",
        "# y_test = []\n",
        "# data_test = []\n",
        "\n",
        "# with open(f'aksharantar_sampled/{indic_lang}/{indic_lang}_train.csv', 'r') as f_train:\n",
        "#   for line in f_train:\n",
        "#     line = line.split(',')\n",
        "#     eng_word = line[0].strip()\n",
        "#     indic_word = line[1].strip()\n",
        "#     X_train.append(eng_word)\n",
        "#     y_train.append(indic_word)\n",
        "#     data_train.append((eng_word, indic_word))\n",
        "\n",
        "# with open(f'aksharantar_sampled/{indic_lang}/{indic_lang}_valid.csv', 'r') as f_val:\n",
        "#   for line in f_val:\n",
        "#     line = line.split(',')\n",
        "#     eng_word = line[0].strip()\n",
        "#     indic_word = line[1].strip()\n",
        "#     X_val.append(eng_word)\n",
        "#     y_val.append(indic_word)\n",
        "#     data_val.append((eng_word, indic_word))\n",
        "\n",
        "# with open(f'aksharantar_sampled/{indic_lang}/{indic_lang}_test.csv', 'r') as f_test:\n",
        "#   for line in f_test:\n",
        "#     line = line.split(',')\n",
        "#     eng_word = line[0].strip()\n",
        "#     indic_word = line[1].strip()\n",
        "#     X_test.append(eng_word)\n",
        "#     y_test.append(indic_word)\n",
        "#     data_test.append((eng_word, indic_word))"
      ],
      "metadata": {
        "id": "k9xBvEb1XGtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(X_train), len(X_val), len(X_test))"
      ],
      "metadata": {
        "id": "HzWBX8ovXpeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train[0].upper(), eng_rep(X_train[0].upper(), eng_alpha2idx))\n",
        "\n",
        "# non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# # Remove all English non-letters\n",
        "# def cleanEnglishVocab(line):\n",
        "#   line = line.upper\n",
        "\n",
        "# def cleanHindiVocab(line):\n",
        "#   pass"
      ],
      "metadata": {
        "id": "fWAR7_-kaf6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransLit_DataLoader(Dataset):\n",
        "  def __init__(self, filename):\n",
        "    self.eng_lang_words, self.indic_lang_words = self.readDataset(filename)\n",
        "    self.shuffle_indices = list(range(len(self.eng_lang_words)))\n",
        "    random.shuffle(self.shuffle_indices)\n",
        "    self.shuffle_start_index = 0\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.eng_lang_words)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.eng_lang_words[idx], self.indic_lang_words[idx]\n",
        "\n",
        "  def readDataset(self, filename):\n",
        "    X = []\n",
        "    y = []\n",
        "    # data = []\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "      for line in f:\n",
        "        line = line.split(',')\n",
        "        eng_word = line[0].strip()\n",
        "        indic_word = line[1].strip()\n",
        "        X.append(eng_word)\n",
        "        y.append(indic_word)\n",
        "        # data_train.append((eng_word, indic_word))\n",
        "    return X, y\n",
        "\n",
        "  def get_random_sample(self):\n",
        "    return self.__getitem__(np.random.randint(len(self.eng_lang_words)))\n",
        "\n",
        "  def get_batch_from_array(self, batch_size, array):\n",
        "    end = self.shuffle_start_index + batch_size\n",
        "    batch = []\n",
        "    if end >= len(self.eng_lang_words):\n",
        "      batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_lang_words)]]\n",
        "    return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index:end]]\n",
        "\n",
        "  def get_batch(self, batch_size, postprocess = True):\n",
        "    eng_lang_batch = self.get_batch_from_array(batch_size, self.eng_lang_words)\n",
        "    indic_lang_batch = self.get_batch_from_array(batch_size, self.indic_lang_words)\n",
        "    self.shuffle_start_index += batch_size + 1\n",
        "\n",
        "    # Reshuffle if 1 epoch is complete\n",
        "    if self.shuffle_start_index >= len(self.eng_lang_words):\n",
        "      random.shuffle(self.shuffle_indices)\n",
        "      self.shuffle_start_index = 0\n",
        "\n",
        "    return eng_lang_batch, indic_lang_batch\n"
      ],
      "metadata": {
        "id": "gFsAOp2ofCB6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_train.csv')\n",
        "data_val = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_valid.csv')\n",
        "data_test = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_test.csv')"
      ],
      "metadata": {
        "id": "Sd0QaLZfvc9S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_train.get_random_sample()"
      ],
      "metadata": {
        "id": "nvSXfZdo0VIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_train.get_batch(8)"
      ],
      "metadata": {
        "id": "bSHytGfe1xRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Data Visualization\n",
        "print('Train Set Size: ', len(data_train))\n",
        "print('Validation Set Size: ', len(data_val))\n",
        "print('Test Set Size: ', len(data_test))\n",
        "eng, indic = data_train.get_random_sample()\n",
        "print(f'Sample data from Train Set: \\n{eng} - {indic}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umwecEOR1d20",
        "outputId": "e81b0eb1-e44c-45c7-eb20-3d9c6bc815e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set Size:  51200\n",
            "Validation Set Size:  4096\n",
            "Test Set Size:  4096\n",
            "Sample data from Train Set: \n",
            "agricultule - एग्रीकल्चल\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding words\n",
        "\n",
        "def eng_rep(eng_word, letter2idx, device = 'cpu'):\n",
        "  eng_word = eng_word.upper()\n",
        "  rep = torch.zeros(len(eng_word) + 1, 1, len(letter2idx)).to(device)\n",
        "  for letter_idx, letter in enumerate(eng_word):\n",
        "    pos = letter2idx[letter]\n",
        "    rep[letter_idx][0][pos] = 1\n",
        "  pad_pos = letter2idx[pad_char]\n",
        "  rep[letter_idx+1][0][pad_pos] = 1\n",
        "  return rep\n",
        "\n",
        "def gt_rep(indic_word, letter2idx, device = 'cpu'):\n",
        "  gt_rep = torch.zeros([len(indic_word) + 1, 1], dtype = torch.long).to(device)\n",
        "  for letter_idx, letter in enumerate(indic_word):\n",
        "    pos = letter2idx[letter]\n",
        "    gt_rep[letter_idx][0] = pos\n",
        "  gt_rep[letter_idx+1][0] = letter2idx[pad_char]\n",
        "  return gt_rep"
      ],
      "metadata": {
        "id": "tRhk67PhZpPS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Encoded Words for English and Indic Language\n",
        "eng_word, indic_word = data_train.get_random_sample()\n",
        "eng_word_rep = eng_rep(eng_word, eng_alpha2idx)\n",
        "indic_word_rep = gt_rep(indic_word, indic_alpha2idx)\n",
        "print(eng_word, eng_word_rep)\n",
        "print(indic_word, indic_word_rep)\n",
        "print(eng_word_rep.shape, indic_word_rep.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgqucCjcvfIR",
        "outputId": "1deaf7c3-feb2-412c-a030-3c3b67f60367"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mhilaaon tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
            "म्हिलाओं tensor([[47],\n",
            "        [78],\n",
            "        [58],\n",
            "        [64],\n",
            "        [51],\n",
            "        [63],\n",
            "        [20],\n",
            "        [ 3],\n",
            "        [ 0]])\n",
            "torch.Size([9, 1, 27]) torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(net, word,max_output_chars, device='cpu'):\n",
        "    net.eval().to(device)\n",
        "    word_ohe = eng_rep(word, eng_alpha2idx)\n",
        "    output = net(word_ohe, max_output_chars)\n",
        "    return output"
      ],
      "metadata": {
        "id": "mwfo3R5ccFE4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "\n",
        "class GRU_EncDec(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "    super(GRU_EncDec, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "    self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "    # Encoder\n",
        "    out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Encoder input', input.shape)\n",
        "      print('Encoder output', out.shape)\n",
        "      print('Encoder hidden', hidden.shape)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_state = hidden\n",
        "    decoder_input = torch.zeros(1,1,self.output_size).to(device)\n",
        "    outputs = []\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Decoder state', decoder_state.shape)\n",
        "      print('Decoder input', decoder_input.shape)\n",
        "\n",
        "    for i in range(max_output_chars):\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder intermediate output', out.shape)\n",
        "\n",
        "      out = self.h2o(decoder_state)\n",
        "      out = self.softmax(out)\n",
        "      outputs.append(out.view(1,-1))\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder output', out.shape)\n",
        "        self.verbose = False\n",
        "\n",
        "      max_idx = torch.argmax(out,2,keepdim = True)\n",
        "\n",
        "      if not ground_truth is None:\n",
        "        max_idx = ground_truth[i].reshape(1,1,1)\n",
        "      \n",
        "      one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "      one_hot.zero_()\n",
        "      one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "      decoder_input = one_hot.detach()\n",
        "    return outputs\n",
        "    "
      ],
      "metadata": {
        "id": "ZzYv9-FiIRaO"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAX_OUTPUT_CHARS = 30\n",
        "\n",
        "# class GRU_EncDec(nn.Module):\n",
        "\n",
        "#   def __init__(self, input_size, hidden_size, output_size, attn=False, verbose=False):\n",
        "#     super(GRU_EncDec, self).__init__()\n",
        "\n",
        "#     self.hidden_size = hidden_size\n",
        "#     self.output_size = output_size\n",
        "#     self.attn = attn\n",
        "\n",
        "#     self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "#     if self.attn:\n",
        "#       self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "#     else:\n",
        "#       self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "\n",
        "#     self.h2o = nn.Linear(hidden_size, output_size)\n",
        "#     self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "#     if self.attn:\n",
        "#       self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "#       self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "#       self.attn_layer = nn.Linear(self.hidden_size, 1)\n",
        "#       self.out2hidden = nn.Linear(self.output_size, self.hidden_size)\n",
        "\n",
        "#     self.verbose = verbose\n",
        "\n",
        "#   def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "#     # Encoder\n",
        "#     if self.attn:\n",
        "#       encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "#       encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "#     else:\n",
        "#       out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "#     if self.verbose:\n",
        "#       print('Encoder input', input.shape)\n",
        "#       if self.attn:\n",
        "#         print('Encoder output', encoder_outputs.shape)\n",
        "#       else:\n",
        "#         print('Encoder output', out.shape)\n",
        "#       print('Encoder hidden', hidden.shape)\n",
        "\n",
        "#     # Decoder\n",
        "#     decoder_state = hidden\n",
        "#     decoder_input = torch.zeros(1,1,self.output_size).to(device)\n",
        "#     outputs = []\n",
        "\n",
        "#     if self.attn:\n",
        "#       U = self.U(encoder_outputs)\n",
        "\n",
        "#     if self.verbose:\n",
        "#       print('Decoder state', decoder_state.shape)\n",
        "#       if self.attn:\n",
        "#         print('Decoder intermediate input', decoder_input.shape)\n",
        "#         print('U*Encoder output', U.shape)\n",
        "#       else:\n",
        "#         print('Decoder input', decoder_input.shape)\n",
        "\n",
        "#     for i in range(max_output_chars):\n",
        "#       if self.attn:\n",
        "#         W = self.W(decoder_state.view(1,-1).repeat(encoder_outputs.shape[0],1))\n",
        "#         V = self.attn_layer(torch.tanh(U+W))\n",
        "\n",
        "#         attn_weights = F.softmax(V.view(1,-1), dim=1)\n",
        "\n",
        "#         if self.verbose:\n",
        "#           print('W*Decoder state', W.shape)\n",
        "#           print('V', V.shape)\n",
        "#           print('Attn_Layer', attn_weights.shape)\n",
        "\n",
        "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "#         embedding = self.out2hidden(decoder_input)\n",
        "#         decoder_input = torch.cat((embedding[0], attn_applied[0]), 1)\n",
        "\n",
        "#         if self.verbose:\n",
        "#           print('Attn LC', attn_applied.shape)\n",
        "#           print('Decoder input', decoder_input.shape)\n",
        "\n",
        "#       out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "#       if self.verbose:\n",
        "#         print('Decoder intermediate output', out.shape)\n",
        "\n",
        "#       out = self.h2o(decoder_state)\n",
        "#       out = self.softmax(out)\n",
        "#       outputs.append(out.view(1,-1))\n",
        "\n",
        "#       if self.verbose:\n",
        "#         print('Decoder output', out.shape)\n",
        "#         self.verbose = False\n",
        "\n",
        "#       max_idx = torch.argmax(out,2,keepdim = True)\n",
        "\n",
        "#       if not ground_truth is None:\n",
        "#         max_idx = ground_truth[i].reshape(1,1,1)\n",
        "      \n",
        "#       one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "#       # one_hot.zero_() ?\n",
        "#       one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "#       decoder_input = one_hot.detach()\n",
        "#     return outputs"
      ],
      "metadata": {
        "id": "8bAgntsZaW2Z"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# net = GRU_EncDec(len(eng_alpha2idx), 1024, len(indic_alpha2idx), verbose=True)"
      ],
      "metadata": {
        "id": "2uBe-EtULVrT"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out = infer(net, 'india', 30)"
      ],
      "metadata": {
        "id": "5QsW-1M3b-I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13815fe-7f04-4d81-e420-fe5cdd420314"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 1024])\n",
            "Encoder hidden torch.Size([1, 1, 1024])\n",
            "Decoder state torch.Size([1, 1, 1024])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 1024])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = data_train.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = eng_rep(eng_batch[i], eng_alpha2idx, device)\n",
        "        gt = gt_rep(hindi_batch[i], indic_alpha2idx, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "metadata": {
        "id": "roXtf-ZxcBWs"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    # (loss_val, batch_ret) =  )\n",
        "    # eng_batch, indic_batch = data_val.get_batch(batch_size)\n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto) )/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i], 'Validation Accuracy: ', calc_word_accuracy(net, data=data_val))\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "            torch.save(net.state_dict(), f'{indic_lang}_model.pth')\n",
        "    return loss_arr"
      ],
      "metadata": {
        "id": "GyZrdrM6e66Z"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = GRU_EncDec(len(eng_alpha2idx), 512, len(indic_alpha2idx))"
      ],
      "metadata": {
        "id": "o-M2ZFWAfD-y"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_setup(net, lr=0.001, n_batches=1500, batch_size = 64, display_freq=100, device = device_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "olNNZlZSfIvF",
        "outputId": "e4883135-aab2-4191-a552-913a3f84ac6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Iteration 299 Loss 0.4087764322757721 Validation Accuracy:  0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(net, device = 'cpu', data = data_val):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    count = 0\n",
        "    for i in range(len(data)):\n",
        "        eng_word, indic_word = data[i]\n",
        "        gt = gt_rep(indic_word, indic_alpha2idx, device)\n",
        "        outputs = infer(net, eng_word, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            \n",
        "            indic_pos = indices.tolist()[0]\n",
        "            if indic_pos[0] == gt[index][0]:\n",
        "              correct += 1\n",
        "            \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(data)\n",
        "        \n",
        "    #     char_level_acc = correct/(gt.shape[0]-1)\n",
        "    #     indic_word_pred = get_indic_pred_word(net, eng_word)\n",
        "        \n",
        "    #     # print(correct, gt.shape[0]-1)\n",
        "    #     # break\n",
        "    #     # print(char_level_acc)\n",
        "        \n",
        "    #     if char_level_acc == 1.0:\n",
        "    #       count += 1\n",
        "    #       print(count)\n",
        "    #       print(f'{eng_word}-{indic_word}-{indic_word_pred}')\n",
        "    #       # accuracy += char_level_acc\n",
        "    # print(len(data))\n",
        "    # accuracy = count/len(data)\n",
        "    \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "YPBFSUsFfnoT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_net = GRU_EncDec(len(eng_alpha2idx), 256, len(indic_alpha2idx), verbose=False)\n",
        "new_net.load_state_dict(torch.load(f'{indic_lang}_model.pth'))"
      ],
      "metadata": {
        "id": "ytsbUKvsINRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2286b68-24dc-4eb7-9d1d-414f02ebf2e6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_indic_pred_word(net, eng_word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, eng_word, 30, device)\n",
        "    # print(outputs)\n",
        "    indic_output = ''\n",
        "    for index, out in enumerate(outputs):\n",
        "      # print(index)\n",
        "      val, indices = out.topk(1)\n",
        "      # print(val)\n",
        "      index = indices.tolist()[0][0]\n",
        "      # print(index)\n",
        "      if index == 0:\n",
        "          break\n",
        "      indic_char = indic_alpha[index+1]\n",
        "      # print(indic_char)\n",
        "      indic_output += indic_char\n",
        "    # print(eng_word + ' - ' + indic_output)\n",
        "    return indic_output"
      ],
      "metadata": {
        "id": "QtI0ht9YfTWy"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indic_alpha.index('ॿ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K--Il6VuypPT",
        "outputId": "a830ac10-ce08-42a7-d37e-2fabe0fccf22"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_word_accuracy(net, device = 'cpu', data = data_val):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    count = 0\n",
        "    for i in range(len(data)):\n",
        "        eng_word, indic_word = data[i]\n",
        "        gt = gt_rep(indic_word, indic_alpha2idx, device)\n",
        "\n",
        "        outputs = infer(net, eng_word, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        indic_output = ''\n",
        "\n",
        "\n",
        "        for index, out in enumerate(outputs):\n",
        "                val, indices = out.topk(1)\n",
        "                \n",
        "                indic_pos = indices.tolist()[0]\n",
        "                # print(indic_pos)\n",
        "                \n",
        "                if indic_pos[0] == gt[index][0]:\n",
        "                  correct += 1\n",
        "                  if indic_pos[0] != 0:\n",
        "                    indic_output += indic_alpha[indic_pos[0]-1]\n",
        "\n",
        "        \n",
        "        char_level_acc = correct/gt.shape[0]\n",
        "\n",
        "        # if index ==2:\n",
        "        #   break\n",
        "        \n",
        "        if char_level_acc == 1.0:\n",
        "          count += 1\n",
        "          # print(f'{eng_word}-{indic_word}-{indic_output}')\n",
        "    print(count)\n",
        "    accuracy = count/len(data)\n",
        "    \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "JGX6eb9RmQuN"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_val = calc_word_accuracy(new_net, data=data_test) * 100\n",
        "# print(indic_alpha2idx)\n",
        "print('Validation Accuracy w/o attention ', accuracy_val)\n"
      ],
      "metadata": {
        "id": "oGCoM3DwNygZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd85450-0e73-438f-a83d-a33b315eb7e4"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "263\n",
            "Validation Accuracy w/o attention  6.4208984375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# new_net = GRU_EncDec(len(eng_alpha2idx), 256, len(indic_alpha2idx), verbose=True)\n",
        "# new_net.load_state_dict(torch.load(\"model.pth\"))\n",
        "accuracy_train = calc_accuracy(new_net, data=data_train) * 100\n",
        "print('Train Accuracy w/o attention ', accuracy_train)\n",
        "accuracy_test = calc_accuracy(new_net, data=data_test) * 100\n",
        "\n",
        "# accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Test Accuracy w/o attention ', accuracy_test)\n",
        "# print('Acurracy with attention', accuracy_attn)"
      ],
      "metadata": {
        "id": "2Z3SjQ92fpsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "82ad0b96-5ae1-4a6d-a0b4-d5489592b772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-d10bd16d6393>\u001b[0m in \u001b[0;36mcalc_accuracy\u001b[0;34m(net, device, data, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0meng_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindic_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindic_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindic_alpha2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# print(len(outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-dce3face66a4>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(net, word, max_output_chars, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mword_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_alpha2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ohe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_output_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-dc102359ab60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, max_output_chars, device, ground_truth)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_rnn_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    999\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m   1000\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "\n",
        "class GRU_EncDec(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size, attn=False, verbose=False):\n",
        "    super(GRU_EncDec, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.attn = attn\n",
        "\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "    if self.attn:\n",
        "      self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "    else:\n",
        "      self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    if self.attn:\n",
        "      self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "      self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "      self.attn_layer = nn.Linear(self.hidden_size, 1)\n",
        "      self.out2hidden = nn.Linear(self.output_size, self.hidden_size)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "    # Encoder\n",
        "    if self.attn:\n",
        "      encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "      encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "    else:\n",
        "      out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Encoder input', input.shape)\n",
        "      if self.attn:\n",
        "        print('Encoder output', encoder_outputs.shape)\n",
        "      else:\n",
        "        print('Encoder output', out.shape)\n",
        "      print('Encoder hidden', hidden.shape)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_state = hidden\n",
        "    decoder_input = torch.zeros(1,1,self.output_size).to(device)\n",
        "    outputs = []\n",
        "\n",
        "    if self.attn:\n",
        "      U = self.U(encoder_outputs)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Decoder state', decoder_state.shape)\n",
        "      if self.attn:\n",
        "        print('Decoder intermediate input', decoder_input.shape)\n",
        "        print('U*Encoder output', U.shape)\n",
        "      else:\n",
        "        print('Decoder input', decoder_input.shape)\n",
        "\n",
        "    for i in range(max_output_chars):\n",
        "      if self.attn:\n",
        "        W = self.W(decoder_state.view(1,-1).repeat(encoder_outputs.shape[0],1))\n",
        "        V = self.attn_layer(torch.tanh(U+W))\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder intermediate output', out.shape)\n",
        "\n",
        "      out = self.h2o(decoder_state)\n",
        "      out = self.softmax(out)\n",
        "      outputs.append(out.view(1,-1))\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder output', out.shape)\n",
        "        self.verbose = False\n",
        "\n",
        "      max_idx = torch.argmax(out,2,keepdim = True)\n",
        "\n",
        "      if not ground_truth is None:\n",
        "        max_idx = ground_truth[i].reshape(1,1,1)\n",
        "      \n",
        "      one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "      one_hot.zero_()\n",
        "      one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "      decoder_input = one_hot.detach()\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "u9jTHqEJhHOy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}