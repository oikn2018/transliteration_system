{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0+8IO5ao2AFIzzNZ89o20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oikn2018/CS6910_assignment_3/blob/main/a3_wo_attn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Commands\n",
        "! pip install wget\n",
        "! pip install gdown\n",
        "! pip install --upgrade gdown\n",
        "# ! pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR290vFmOUDY",
        "outputId": "6ed2a10c-d61b-467b-fa91-1113be7f61b7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import gdown\n",
        "# import wandb\n",
        "from io import open\n",
        "import string, time, math\n",
        "import wget\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.data import Dataset\n",
        "import re"
      ],
      "metadata": {
        "id": "yPP3T6frM-uq"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "# CUDA\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "# torch.backends.cudnn.deterministic=True\n",
        "# torch.backends.cudnn.benchmark=False"
      ],
      "metadata": {
        "id": "QrFxXQDRVD5P"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_gpu = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "CNoiOBN5NSoh"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the Dataset\n",
        "url = 'https://drive.google.com/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download'\n",
        "# filename = os.path.basename(url)\n",
        "# print(filename)\n",
        "\n",
        "if not os.path.exists(\"aksharantar_sampled\"):\n",
        "  filename = gdown.download(url = url, quiet=False, fuzzy=True)\n",
        "  print(filename)\n",
        "  with ZipFile(filename, 'r') as z:\n",
        "    print('Extracting files...')\n",
        "    z.extractall()\n",
        "    print('Done!')\n",
        "  os.remove(filename)"
      ],
      "metadata": {
        "id": "CqymbOGsQCSh"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_alpha = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '<PAD>'\n",
        "\n",
        "eng_alpha2idx = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alpha):\n",
        "  eng_alpha2idx[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3jjj7_pQphV",
        "outputId": "831097d2-d933-4330-cf6f-68adf62fee61"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<PAD>': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change Indic Language here\n",
        "# indic_lang = 'ben'\n",
        "indic_lang = 'hin'"
      ],
      "metadata": {
        "id": "Ld_X-RaYMzCv"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bengali Unicode Hex Range: 2432-2558\n",
        "# Hindi Unicode Hex Range: 2304-2431\n",
        "\n",
        "min_range = 2304\n",
        "max_range = 2431\n",
        "\n",
        "if indic_lang == 'ben':\n",
        "  min_range = 2432\n",
        "  max_range = 2558\n",
        "elif indic_lang == 'hindi':\n",
        "  min_range = 2304\n",
        "  max_range = 2431\n",
        "\n",
        "indic_alpha = [chr(alpha) for alpha in range(min_range, max_range + 1)]\n",
        "print(indic_alpha)\n",
        "indic_alpha_size = len(indic_alpha)\n",
        "\n",
        "indic_alpha2idx = {pad_char: 0}\n",
        "for index, alpha in enumerate(indic_alpha):\n",
        "  indic_alpha2idx[alpha] = index+1\n",
        "\n",
        "print(indic_alpha2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0PjyADuTfHv",
        "outputId": "257e818f-30ed-4b42-8228-558280f23828"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ', 'ॿ']\n",
            "{'<PAD>': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3kFrEXzLbZ3c"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indic_langs = sorted([indic_lang for indic_lang in os.listdir(\"aksharantar_sampled\") if indic_lang != '.DS_Store'])\n",
        "print(indic_langs)"
      ],
      "metadata": {
        "id": "RqbEtORMbreO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c6c536-c335-480f-e02e-ead66981e50d"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['asm', 'ben', 'brx', 'guj', 'hin', 'kan', 'kas', 'kok', 'mai', 'mal', 'mar', 'mni', 'ori', 'pan', 'san', 'sid', 'tam', 'tel', 'urd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = []\n",
        "# y_train = []\n",
        "# data_train = []\n",
        "\n",
        "# X_val = []\n",
        "# y_val = []\n",
        "# data_val = []\n",
        "\n",
        "# X_test = []\n",
        "# y_test = []\n",
        "# data_test = []\n",
        "\n",
        "# with open(f'aksharantar_sampled/{indic_lang}/{indic_lang}_train.csv', 'r') as f_train:\n",
        "#   for line in f_train:\n",
        "#     line = line.split(',')\n",
        "#     eng_word = line[0].strip()\n",
        "#     indic_word = line[1].strip()\n",
        "#     X_train.append(eng_word)\n",
        "#     y_train.append(indic_word)\n",
        "#     data_train.append((eng_word, indic_word))\n",
        "\n",
        "# with open(f'aksharantar_sampled/{indic_lang}/{indic_lang}_valid.csv', 'r') as f_val:\n",
        "#   for line in f_val:\n",
        "#     line = line.split(',')\n",
        "#     eng_word = line[0].strip()\n",
        "#     indic_word = line[1].strip()\n",
        "#     X_val.append(eng_word)\n",
        "#     y_val.append(indic_word)\n",
        "#     data_val.append((eng_word, indic_word))\n",
        "\n",
        "# with open(f'aksharantar_sampled/{indic_lang}/{indic_lang}_test.csv', 'r') as f_test:\n",
        "#   for line in f_test:\n",
        "#     line = line.split(',')\n",
        "#     eng_word = line[0].strip()\n",
        "#     indic_word = line[1].strip()\n",
        "#     X_test.append(eng_word)\n",
        "#     y_test.append(indic_word)\n",
        "#     data_test.append((eng_word, indic_word))"
      ],
      "metadata": {
        "id": "k9xBvEb1XGtj"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(X_train), len(X_val), len(X_test))"
      ],
      "metadata": {
        "id": "HzWBX8ovXpeI"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train[0].upper(), eng_rep(X_train[0].upper(), eng_alpha2idx))\n",
        "\n",
        "# non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# # Remove all English non-letters\n",
        "# def cleanEnglishVocab(line):\n",
        "#   line = line.upper\n",
        "\n",
        "# def cleanHindiVocab(line):\n",
        "#   pass"
      ],
      "metadata": {
        "id": "fWAR7_-kaf6M"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransLit_DataLoader(Dataset):\n",
        "  def __init__(self, filename):\n",
        "    self.eng_lang_words, self.indic_lang_words = self.readDataset(filename)\n",
        "    self.shuffle_indices = list(range(len(self.eng_lang_words)))\n",
        "    random.shuffle(self.shuffle_indices)\n",
        "    self.shuffle_start_index = 0\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.eng_lang_words)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.eng_lang_words[idx], self.indic_lang_words[idx]\n",
        "\n",
        "  def readDataset(self, filename):\n",
        "    X = []\n",
        "    y = []\n",
        "    # data = []\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "      for line in f:\n",
        "        line = line.split(',')\n",
        "        eng_word = line[0].strip()\n",
        "        indic_word = line[1].strip()\n",
        "        X.append(eng_word)\n",
        "        y.append(indic_word)\n",
        "        # data_train.append((eng_word, indic_word))\n",
        "    return X, y\n",
        "\n",
        "  def get_random_sample(self):\n",
        "    return self.__getitem__(np.random.randint(len(self.eng_lang_words)))\n",
        "\n",
        "  def get_batch_from_array(self, batch_size, array):\n",
        "    end = self.shuffle_start_index + batch_size\n",
        "    batch = []\n",
        "    if end >= len(self.eng_lang_words):\n",
        "      batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_lang_words)]]\n",
        "    return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index:end]]\n",
        "\n",
        "  def get_batch(self, batch_size, postprocess = True):\n",
        "    eng_lang_batch = self.get_batch_from_array(batch_size, self.eng_lang_words)\n",
        "    indic_lang_batch = self.get_batch_from_array(batch_size, self.indic_lang_words)\n",
        "    self.shuffle_start_index += batch_size + 1\n",
        "\n",
        "    # Reshuffle if 1 epoch is complete\n",
        "    if self.shuffle_start_index >= len(self.eng_lang_words):\n",
        "      random.shuffle(self.shuffle_indices)\n",
        "      self.shuffle_start_index = 0\n",
        "\n",
        "    return eng_lang_batch, indic_lang_batch\n"
      ],
      "metadata": {
        "id": "gFsAOp2ofCB6"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_train.csv')\n",
        "data_val = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_valid.csv')\n",
        "data_test = TransLit_DataLoader(f'aksharantar_sampled/{indic_lang}/{indic_lang}_test.csv')"
      ],
      "metadata": {
        "id": "Sd0QaLZfvc9S"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_train.get_random_sample()"
      ],
      "metadata": {
        "id": "nvSXfZdo0VIZ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_train.get_batch(8)"
      ],
      "metadata": {
        "id": "bSHytGfe1xRx"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Data Visualization\n",
        "print('Train Set Size: ', len(data_train))\n",
        "print('Validation Set Size: ', len(data_val))\n",
        "print('Test Set Size: ', len(data_test))\n",
        "eng, indic = data_train.get_random_sample()\n",
        "print(f'Sample data from Train Set: \\n{eng} - {indic}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umwecEOR1d20",
        "outputId": "cec2de06-1f2c-481b-cb0e-eab1d16de285"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set Size:  51200\n",
            "Validation Set Size:  4096\n",
            "Test Set Size:  4096\n",
            "Sample data from Train Set: \n",
            "agricultule - एग्रीकल्चल\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding words\n",
        "\n",
        "def eng_rep(eng_word, letter2idx, device = 'cpu'):\n",
        "  eng_word = eng_word.upper()\n",
        "  rep = torch.zeros(len(eng_word) + 1, 1, len(letter2idx)).to(device)\n",
        "  for letter_idx, letter in enumerate(eng_word):\n",
        "    pos = letter2idx[letter]\n",
        "    rep[letter_idx][0][pos] = 1\n",
        "  pad_pos = letter2idx[pad_char]\n",
        "  rep[letter_idx+1][0][pad_pos] = 1\n",
        "  return rep\n",
        "\n",
        "def gt_rep(indic_word, letter2idx, device = 'cpu'):\n",
        "  gt_rep = torch.zeros([len(indic_word) + 1, 1], dtype = torch.long).to(device)\n",
        "  for letter_idx, letter in enumerate(indic_word):\n",
        "    pos = letter2idx[letter]\n",
        "    gt_rep[letter_idx][0] = pos\n",
        "  gt_rep[letter_idx+1][0] = letter2idx[pad_char]\n",
        "  return gt_rep"
      ],
      "metadata": {
        "id": "tRhk67PhZpPS"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Encoded Words for English and Indic Language\n",
        "eng_word, indic_word = data_train.get_random_sample()\n",
        "eng_word_rep = eng_rep(eng_word, eng_alpha2idx)\n",
        "indic_word_rep = gt_rep(indic_word, indic_alpha2idx)\n",
        "print(eng_word, eng_word_rep)\n",
        "print(indic_word, indic_word_rep)\n",
        "print(eng_word_rep.shape, indic_word_rep.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgqucCjcvfIR",
        "outputId": "d4bca739-d261-41c5-843f-340fa9392567"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mhilaaon tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
            "म्हिलाओं tensor([[47],\n",
            "        [78],\n",
            "        [58],\n",
            "        [64],\n",
            "        [51],\n",
            "        [63],\n",
            "        [20],\n",
            "        [ 3],\n",
            "        [ 0]])\n",
            "torch.Size([9, 1, 27]) torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(net, word,max_output_chars, device='cpu'):\n",
        "    net.eval().to(device)\n",
        "    word_ohe = eng_rep(word, eng_alpha2idx)\n",
        "    output = net(word_ohe, max_output_chars)\n",
        "    return output"
      ],
      "metadata": {
        "id": "mwfo3R5ccFE4"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "\n",
        "class GRU_EncDec(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "    super(GRU_EncDec, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "    self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "    # Encoder\n",
        "    out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Encoder input', input.shape)\n",
        "      print('Encoder output', out.shape)\n",
        "      print('Encoder hidden', hidden.shape)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_state = hidden\n",
        "    decoder_input = torch.zeros(1,1,self.output_size).to(device)\n",
        "    outputs = []\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Decoder state', decoder_state.shape)\n",
        "      print('Decoder input', decoder_input.shape)\n",
        "\n",
        "    for i in range(max_output_chars):\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder intermediate output', out.shape)\n",
        "\n",
        "      out = self.h2o(decoder_state)\n",
        "      out = self.softmax(out)\n",
        "      outputs.append(out.view(1,-1))\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder output', out.shape)\n",
        "        self.verbose = False\n",
        "\n",
        "      max_idx = torch.argmax(out,2,keepdim = True)\n",
        "\n",
        "      if not ground_truth is None:\n",
        "        max_idx = ground_truth[i].reshape(1,1,1)\n",
        "      \n",
        "      one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "      one_hot.zero_()\n",
        "      one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "      decoder_input = one_hot.detach()\n",
        "    return outputs\n",
        "    "
      ],
      "metadata": {
        "id": "ZzYv9-FiIRaO"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = GRU_EncDec(len(eng_alpha2idx), 256, len(indic_alpha2idx), verbose=True)"
      ],
      "metadata": {
        "id": "2uBe-EtULVrT"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = infer(net, 'india', 30)"
      ],
      "metadata": {
        "id": "5QsW-1M3b-I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf979b3-0257-4d29-ce90-846d815fb9ec"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = data_train.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = eng_rep(eng_batch[i], eng_alpha2idx, device)\n",
        "        gt = gt_rep(hindi_batch[i], indic_alpha2idx, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "metadata": {
        "id": "roXtf-ZxcBWs"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    # (loss_val, batch_ret) =  )\n",
        "    # eng_batch, indic_batch = data_val.get_batch(batch_size)\n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto) )/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i], 'Validation Accuracy: ', calc_accuracy(net, data=data_val))\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "            torch.save(net.state_dict(), f'{indic_lang}_model.pth')\n",
        "    return loss_arr"
      ],
      "metadata": {
        "id": "GyZrdrM6e66Z"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = GRU_EncDec(len(eng_alpha2idx), 256, len(indic_alpha2idx))"
      ],
      "metadata": {
        "id": "o-M2ZFWAfD-y"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=100, device = device_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "olNNZlZSfIvF",
        "outputId": "481587f0-76f1-4742-ab0d-8d40e5a615e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1599 Loss 0.3225618600845337 Validation Accuracy:  0.5437365354480831\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_net = GRU_EncDec(len(eng_alpha2idx), 256, len(indic_alpha2idx), verbose=False)\n",
        "new_net.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "id": "ytsbUKvsINRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdc85e6-b5fd-46af-f1ad-7d6862eee17c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_indic_pred_word(net, eng_word, k = 1, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, eng_word, 30, device)\n",
        "    # print(outputs)\n",
        "    indic_output = ''\n",
        "    for index, out in enumerate(outputs):\n",
        "      # print(index)\n",
        "      val, indices = out.topk(k)\n",
        "      # print(val)\n",
        "      index = indices.tolist()[0][0]\n",
        "      print(index)\n",
        "      if index == 0:\n",
        "          break\n",
        "      indic_char = indic_alpha[index+1]\n",
        "      print(indic_char)\n",
        "      indic_output += indic_char\n",
        "    # print(eng_word + ' - ' + indic_output)\n",
        "    return indic_output"
      ],
      "metadata": {
        "id": "QtI0ht9YfTWy"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_indic_pred_word(new_net, eng_word='oncholke', k=1)"
      ],
      "metadata": {
        "id": "L3m7xmSSH4bV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "53c7a73a-8390-4e49-e004-1df741839c55"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "ম\n",
            "63\n",
            "ী\n",
            "49\n",
            "ল\n",
            "63\n",
            "ী\n",
            "63\n",
            "ী\n",
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'মীলীী'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(net, device = 'cpu', data = data_val):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(data)):\n",
        "        eng_word, indic_word = data[i]\n",
        "        gt = gt_rep(indic_word, indic_alpha2idx, device)\n",
        "        outputs = infer(net, eng_word, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            \n",
        "            indic_pos = indices.tolist()[0]\n",
        "            if indic_pos[0] == gt[index][0]:\n",
        "              correct += 1\n",
        "        \n",
        "        char_level_acc = correct/gt.shape[0]\n",
        "        accuracy += char_level_acc\n",
        "    # print(len(data))\n",
        "    accuracy /= len(data)\n",
        "    \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "YPBFSUsFfnoT"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_val = calc_accuracy(new_net, data=data_val) * 100\n",
        "print('Validation Accuracy w/o attention ', accuracy_val)\n"
      ],
      "metadata": {
        "id": "oGCoM3DwNygZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8385851-828e-423e-af6c-8b83274da2ae"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4096\n",
            "Validation Accuracy w/o attention  12.141146615271134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# new_net = GRU_EncDec(len(eng_alpha2idx), 256, len(indic_alpha2idx), verbose=True)\n",
        "# new_net.load_state_dict(torch.load(\"model.pth\"))\n",
        "accuracy_train = calc_accuracy(new_net, data=data_train) * 100\n",
        "print('Train Accuracy w/o attention ', accuracy_train)\n",
        "accuracy_test = calc_accuracy(new_net, data=data_test) * 100\n",
        "\n",
        "# accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Test Accuracy w/o attention ', accuracy_test)\n",
        "# print('Acurracy with attention', accuracy_attn)"
      ],
      "metadata": {
        "id": "2Z3SjQ92fpsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "82ad0b96-5ae1-4a6d-a0b4-d5489592b772"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-d10bd16d6393>\u001b[0m in \u001b[0;36mcalc_accuracy\u001b[0;34m(net, device, data, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0meng_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindic_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindic_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindic_alpha2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# print(len(outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-dce3face66a4>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(net, word, max_output_chars, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mword_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_alpha2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ohe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_output_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-dc102359ab60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, max_output_chars, device, ground_truth)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_rnn_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    999\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m   1000\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "\n",
        "class GRU_EncDec(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size, attn=False, verbose=False):\n",
        "    super(GRU_EncDec, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.attn = attn\n",
        "\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "    if self.attn:\n",
        "      self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "    else:\n",
        "      self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    if self.attn:\n",
        "      self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "      self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "      self.attn_layer = nn.Linear(self.hidden_size, 1)\n",
        "      self.out2hidden = nn.Linear(self.output_size, self.hidden_size)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "    # Encoder\n",
        "    if self.attn:\n",
        "      encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "      encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "    else:\n",
        "      out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Encoder input', input.shape)\n",
        "      if self.attn:\n",
        "        print('Encoder output', encoder_outputs.shape)\n",
        "      else:\n",
        "        print('Encoder output', out.shape)\n",
        "      print('Encoder hidden', hidden.shape)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_state = hidden\n",
        "    decoder_input = torch.zeros(1,1,self.output_size).to(device)\n",
        "    outputs = []\n",
        "\n",
        "    if self.attn:\n",
        "      U = self.U(encoder_outputs)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Decoder state', decoder_state.shape)\n",
        "      if self.attn:\n",
        "        print('Decoder intermediate input', decoder_input.shape)\n",
        "        print('U*Encoder output', U.shape)\n",
        "      else:\n",
        "        print('Decoder input', decoder_input.shape)\n",
        "\n",
        "    for i in range(max_output_chars):\n",
        "      if self.attn:\n",
        "        W = self.W(decoder_state.view(1,-1).repeat(encoder_outputs.shape[0],1))\n",
        "        V = self.attn_layer(torch.tanh(U+W))\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder intermediate output', out.shape)\n",
        "\n",
        "      out = self.h2o(decoder_state)\n",
        "      out = self.softmax(out)\n",
        "      outputs.append(out.view(1,-1))\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder output', out.shape)\n",
        "        self.verbose = False\n",
        "\n",
        "      max_idx = torch.argmax(out,2,keepdim = True)\n",
        "\n",
        "      if not ground_truth is None:\n",
        "        max_idx = ground_truth[i].reshape(1,1,1)\n",
        "      \n",
        "      one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "      one_hot.zero_()\n",
        "      one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "      decoder_input = one_hot.detach()\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "u9jTHqEJhHOy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}